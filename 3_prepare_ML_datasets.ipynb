{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o8Qof7Cy165"
   },
   "source": [
    "# 3_prepare_data_babyweight\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "1. Setup up the environment\n",
    "1. Preprocess natality dataset\n",
    "1. Augment natality dataset\n",
    "1. Create the train and eval tables in BigQuery\n",
    "1. Export data from BigQuery to GCS in CSV format\n",
    "\n",
    "\n",
    "## Introduction \n",
    "In this notebook, we will prepare the babyweight dataset for model development and training to predict the weight of a baby before it is born.  We will use BigQuery to perform data augmentation and preprocessing which will be used for AutoML Tables, BigQuery ML, and Keras models trained on Cloud AI Platform.\n",
    "\n",
    "In this lab, we will set up the environment, create the project dataset, preprocess and augment natality dataset, create the train and eval tables in BigQuery, and export data from BigQuery to GCS in CSV format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "## Set up environment variables and load necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJ_C-hvutYRD"
   },
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UpUkLEYKtYRE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"predict-babyweight-10142021\"\n",
    "BUCKET = PROJECT\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET \n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a BigQuery Dataset\n",
    "\n",
    "A BigQuery dataset is a container for tables, views, and models built with BigQuery ML. Let's create one called __babyweight__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery dataset already exists, let's not recreate it.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a BigQuery dataset for babyweight if it doesn't exist\n",
    "datasetexists=$(bq ls -d | grep -w babyweight)\n",
    "\n",
    "if [ -n \"$datasetexists\" ]; then\n",
    "    echo -e \"BigQuery dataset already exists, let's not recreate it.\"\n",
    "\n",
    "else\n",
    "    echo \"Creating BigQuery dataset titled: babyweight\"\n",
    "    \n",
    "    bq --location=US mk --dataset \\\n",
    "        --description \"Babyweight\" \\\n",
    "        $PROJECT:babyweight\n",
    "    echo \"Here are the current datasets:\"\n",
    "    bq ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2TuS1s9vREL"
   },
   "source": [
    "## Create the training and evaluation data tables\n",
    "\n",
    "First we are going to create a subset of the data limiting our columns to `weight_pounds`, `is_male`, `mother_age`, `plurality`, and `gestation_weeks` as well as some simple filtering and a column to hash on for repeatable splitting.\n",
    "\n",
    "* Note:  The dataset in the create table code below is the one created previously, e.g. \"babyweight\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vGyv3WntYRH"
   },
   "source": [
    "### Preprocess and filter dataset\n",
    "\n",
    "We have some preprocessing and filtering we would like to do to get our data in the right format for training.\n",
    "\n",
    "Preprocessing:\n",
    "* Cast `is_male` from `BOOL` to `STRING`\n",
    "* Cast `plurality` from `INTEGER` to `STRING` where `[1, 2, 3, 4, 5]` becomes `[\"Single(1)\", \"Twins(2)\", \"Triplets(3)\", \"Quadruplets(4)\", \"Quintuplets(5)\"]`\n",
    "* Cast `cigarette_use`from `BOOL` to `STRING` where `NULL` becomes `Unknown`\n",
    "* Cast `alcohol_use`from `BOOL` to `STRING` where `NULL` becomes `Unknown`\n",
    "* Add `hashcolumn` hashing on `year`, `month`,`COALESCE(wday, day, 0)`,`IFNULL(state, \"Unknown\")`, and `IFNULL(mother_birth_state, \"Unknown\")`\n",
    "\n",
    "Filtering:\n",
    "* Only want data for years later than `2003`\n",
    "* Only want baby weights greater than `0`\n",
    "* Only want mothers whose age is greater than `0`\n",
    "* Only want plurality to be greater than `0`\n",
    "* Only want the number of weeks of gestation to be greater than `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "evDq3h3NtYRH",
    "outputId": "98403982-bb6e-41c2-b114-bc066b5c8c5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE\n",
    "    babyweight.babyweight_2003 AS\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    CAST(is_male AS STRING) AS is_male,\n",
    "    mother_age,\n",
    "    CASE\n",
    "        WHEN plurality = 1 THEN \"Single(1)\"\n",
    "        WHEN plurality = 2 THEN \"Twins(2)\"\n",
    "        WHEN plurality = 3 THEN \"Triplets(3)\"\n",
    "        WHEN plurality = 4 THEN \"Quadruplets(4)\"\n",
    "        WHEN plurality = 5 THEN \"Quintuplets(5)\"\n",
    "    END AS plurality,\n",
    "    gestation_weeks,\n",
    "    IFNULL(CAST(cigarette_use AS STRING), \"Unknown\") AS cigarette_use,\n",
    "    IFNULL(CAST(alcohol_use AS STRING), \"Unknown\") AS alcohol_use,\n",
    "    ABS(FARM_FINGERPRINT(\n",
    "        CONCAT(\n",
    "            CAST(year AS STRING),\n",
    "            CAST(month AS STRING),\n",
    "            CAST(COALESCE(wday, day, 0)  AS STRING),\n",
    "            CAST(IFNULL(state, \"Unknown\") AS STRING),\n",
    "            CAST(IFNULL(mother_birth_state, \"Unknown\")  AS STRING)\n",
    "        )\n",
    "    )) AS hash_values\n",
    "FROM\n",
    "    publicdata.samples.natality\n",
    "WHERE\n",
    "    year > 2002\n",
    "    AND weight_pounds > 0\n",
    "    AND mother_age > 0\n",
    "    AND plurality > 0\n",
    "    AND gestation_weeks > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzUvUKWJtYRI"
   },
   "source": [
    "### Augment dataset to simulate missing data\n",
    "\n",
    "Now we want to augment our dataset with our simulated babyweight data by setting all gender information to `Unknown` and setting plurality of all non-single births to `Multiple(2+)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jrxcoig7tYRI",
    "outputId": "88c1e38e-d8fe-4225-880a-67e98a01f6ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE\n",
    "    babyweight.babyweight_2003_augmented AS\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    cigarette_use,\n",
    "    alcohol_use,\n",
    "    hash_values\n",
    "FROM\n",
    "    babyweight.babyweight_2003\n",
    "UNION ALL\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    \"Unknown\" AS is_male,\n",
    "    mother_age,\n",
    "    CASE\n",
    "        WHEN plurality = \"Single(1)\" THEN plurality\n",
    "        ELSE \"Multiple(2+)\"\n",
    "    END AS plurality,\n",
    "    gestation_weeks,\n",
    "    cigarette_use,\n",
    "    alcohol_use,\n",
    "    hash_values\n",
    "FROM\n",
    "    babyweight.babyweight_2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHgRpfa1tYRJ"
   },
   "source": [
    "### Split augmented dataset into train and eval sets\n",
    "\n",
    "Using ` hash_values`, apply a modulo to get approximately a 80/15/5 train/eval/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bzropn5tYRJ"
   },
   "source": [
    "#### Split augmented dataset into train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CMNRractvREL",
    "outputId": "0aa9d6f8-db89-4fd5-e012-4fd1657d30ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE\n",
    "    babyweight.babyweight_2003_train AS\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    cigarette_use,\n",
    "    alcohol_use,\n",
    "FROM\n",
    "    babyweight.babyweight_2003_augmented\n",
    "WHERE\n",
    "    MOD(hash_values, 100) < 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b23PfPJJtYRK"
   },
   "source": [
    "#### Split augmented dataset into eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B2vJfGObtYRK",
    "outputId": "14c2c8c7-39cf-4077-b69c-ccf69f1331f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE\n",
    "    babyweight.babyweight_2003_eval AS\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    cigarette_use,\n",
    "    alcohol_use,\n",
    "FROM\n",
    "    babyweight.babyweight_2003_augmented\n",
    "WHERE\n",
    "    MOD(hash_values, 100) >= 80\n",
    "    AND MOD(hash_values, 100) < 95\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split augmented dataset into test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE\n",
    "    babyweight.babyweight_2003_test AS\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    cigarette_use,\n",
    "    alcohol_use,\n",
    "FROM\n",
    "    babyweight.babyweight_2003_augmented\n",
    "WHERE\n",
    "    MOD(hash_values, 100) >= 95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clnaaqQsXkwC"
   },
   "source": [
    "## Verify table creation\n",
    "\n",
    "Verify that you created the dataset and training data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lGvtTitXtYRL",
    "outputId": "e0e83d86-75f3-4989-fc8b-fd29f481a563"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>cigarette_use</th>\n",
       "      <th>alcohol_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [weight_pounds, is_male, mother_age, plurality, gestation_weeks, cigarette_use, alcohol_use]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "-- LIMIT 0 is a free query; this allows us to check that the table exists.\n",
    "SELECT * FROM babyweight.babyweight_2003_train\n",
    "LIMIT 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "o2Ctc9QPtYRL",
    "outputId": "b68c3171-d63e-4134-c0ff-7fc0110bc221"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>cigarette_use</th>\n",
       "      <th>alcohol_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [weight_pounds, is_male, mother_age, plurality, gestation_weeks, cigarette_use, alcohol_use]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "-- LIMIT 0 is a free query; this allows us to check that the table exists.\n",
    "SELECT * FROM babyweight.babyweight_2003_eval\n",
    "LIMIT 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hY5O4Mg2tYRL"
   },
   "source": [
    "## Export from BigQuery to CSVs in GCS\n",
    "\n",
    "Use BigQuery Python API to export our train, eval, and test tables to Google Cloud Storage in the CSV format to be used later for TensorFlow/Keras training. \n",
    "\n",
    "We'll want to use the dataset we've been using above as well as repeat the process for both training, evaluation, and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-Z1QbVdWtYRL",
    "outputId": "fea16d12-3b72-4148-8d87-4edad50fbedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported predict-babyweight-10142021:babyweight.babyweight_2003_train \n",
      " to gs://predict-babyweight-10142021/babyweight/data/train*.csv\n",
      "Exported predict-babyweight-10142021:babyweight.babyweight_2003_eval \n",
      " to gs://predict-babyweight-10142021/babyweight/data/eval*.csv\n",
      "Exported predict-babyweight-10142021:babyweight.babyweight_2003_test \n",
      " to gs://predict-babyweight-10142021/babyweight/data/test*.csv\n"
     ]
    }
   ],
   "source": [
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "dataset_name = \"babyweight\"\n",
    "\n",
    "# Create dataset reference object\n",
    "dataset_ref = client.dataset(\n",
    "    dataset_id=dataset_name, project=client.project)\n",
    "\n",
    "# Export both train and eval tables\n",
    "for step in [\"train\", \"eval\", \"test\"]:\n",
    "    destination_uri = os.path.join(\n",
    "        \"gs://\", BUCKET, dataset_name, \"data\", f\"{step}*.csv\")\n",
    "    table_name = f\"babyweight_2003_{step}\"\n",
    "    table_ref = dataset_ref.table(table_name)\n",
    "    extract_job = client.extract_table(\n",
    "        table_ref,\n",
    "        destination_uri,\n",
    "        location=\"US\", # Location must match that of the source table.\n",
    "    )  # API request\n",
    "    extract_job.result()  # Waits for job to complete.\n",
    "\n",
    "    print(f\"Exported {client.project}:{dataset_name}.{table_name} \\n to {destination_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPUXobrwtYRM"
   },
   "source": [
    "## Verify CSV creation\n",
    "\n",
    "Verify that we correctly created the CSV files in our bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iI2Q91qxtYRM",
    "outputId": "84010e2b-3f8c-4218-eca5-403d194d95fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://predict-babyweight-10142021/babyweight/data/eval000000000000.csv\n",
      "gs://predict-babyweight-10142021/babyweight/data/test000000000000.csv\n",
      "gs://predict-babyweight-10142021/babyweight/data/train000000000000.csv\n",
      "gs://predict-babyweight-10142021/babyweight/data/train000000000001.csv\n",
      "gs://predict-babyweight-10142021/babyweight/data/train000000000002.csv\n",
      "gs://predict-babyweight-10142021/babyweight/data/train000000000003.csv\n",
      "gs://predict-babyweight-10142021/babyweight/data/train000000000004.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/babyweight/data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TxPE2peWtYRN",
    "outputId": "b5494ae5-9254-47a1-891b-da99c26f80a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_pounds,is_male,mother_age,plurality,gestation_weeks,cigarette_use,alcohol_use\n",
      "1.43741394824,false,15,Single(1),22,false,false\n",
      "2.12525620568,false,42,Single(1),30,Unknown,Unknown\n",
      "2.18698563904,Unknown,42,Single(1),31,false,false\n",
      "6.3382900325,Unknown,43,Multiple(2+),45,false,false\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cat gs://predict-babyweight-10142021/babyweight/data/test000000000000.csv | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rnEAXNRytYRN",
    "outputId": "260b4eb5-e1b1-4de7-9a9c-a81bba763e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_pounds,is_male,mother_age,plurality,gestation_weeks,cigarette_use,alcohol_use\n",
      "5.56226287026,true,15,Single(1),31,false,false\n",
      "4.629707502,true,46,Twins(2),28,false,false\n",
      "2.0502990366,true,46,Twins(2),26,Unknown,Unknown\n",
      "1.4991433816,true,43,Single(1),18,Unknown,Unknown\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cat gs://predict-babyweight-10142021/babyweight/data/eval000000000000.csv| head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil cat gs://predict-babyweight-10142021/babyweight/data/test000000000000.csv| head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCTvP7MhtYRN"
   },
   "source": [
    "## Summary: \n",
    "In this notebook, we setup our environment, created a BigQuery dataset, preprocessed and augmented the natality dataset, created train and eval tables in BigQuery, and exported data from BigQuery to GCS in CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1888a97",
   "metadata": {},
   "source": [
    "# 3_create_ML_dataset_using_Dataflow\n",
    "\n",
    "In this notebook, we'll use Cloud Dataflow to preprocess the entire dataset from BigQuery and create CSV files for the training/evaluation datasets for operationalizing the ML model later.\n",
    "\n",
    "Some benefits of using Dataflow:\n",
    "- Dataflow sets itself apart as a platform for data transformations because it is a serverless, fully managed offering from Google that allows you to execute Data Processing Pipelines at scale.\n",
    "- Dataflow executes our code using the Apache Beam API. Apache Beam supports both batch and streaming processing using the same pipeline code.\n",
    "- Dataflow changes the amount of compute resources, the number of servers that will run your pipeline elastically, all depending on the amount of data that your pipeline needs to process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afccbb9",
   "metadata": {},
   "source": [
    "## Import necessary libraries & Set up environment variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dca5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user google-cloud-bigquery==1.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361302a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user apache-beam[interactive]==2.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf25e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24.0\n",
      "2.3.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import datetime\n",
    "from google.cloud import bigquery\n",
    "import apache_beam as beam\n",
    "print(beam.__version__)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04e3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import copy\n",
    "import shutil\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50272e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"predict-babyweight-10142021\"\n",
    "BUCKET = PROJECT\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET \n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce17525",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls|grep -q gs://${BUCKET}/; then\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89efd43",
   "metadata": {},
   "source": [
    "## Call BigQuery and examine in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67820340",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d0cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2003 = \"\"\"\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    CAST(is_male AS STRING) AS is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    IFNULL(CAST(cigarette_use AS STRING), \"Unknown\") AS cigarette_use,\n",
    "    IFNULL(CAST(alcohol_use AS STRING), \"Unknown\") AS alcohol_use,\n",
    "    year,\n",
    "    month,\n",
    "    COALESCE(wday, day, 0) AS date,\n",
    "    IFNULL(state, \"Unknown\") AS state,\n",
    "    IFNULL(mother_birth_state, \"Unknown\") AS mother_birth_state\n",
    "FROM\n",
    "    publicdata.samples.natality\n",
    "WHERE\n",
    "    year > 2002\n",
    "    AND weight_pounds > 0\n",
    "    AND mother_age > 0\n",
    "    AND plurality > 0\n",
    "    AND gestation_weeks > 0\n",
    "\"\"\"\n",
    "\n",
    "query_2003_with_hash_vals=f\"\"\"\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    cigarette_use,\n",
    "    alcohol_use,\n",
    "    ABS(FARM_FINGERPRINT(\n",
    "        CONCAT(\n",
    "            CAST(year AS STRING),\n",
    "            CAST(month AS STRING),\n",
    "            CAST(date AS STRING),\n",
    "            CAST(state AS STRING),\n",
    "            CAST(mother_birth_state AS STRING)\n",
    "        )\n",
    "    )) AS hash_values\n",
    "FROM\n",
    "    ({query_2003})\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2ce96",
   "metadata": {},
   "source": [
    "Let's find how many records from the `query_2003` call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355d6831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Number of all records found: 25037335\n"
     ]
    }
   ],
   "source": [
    "query_2003_count = f\"SELECT COUNT(*) FROM ({query_2003})\"\n",
    "df_count = bq.query(query_2003_count).to_dataframe()\n",
    "num_records = df_count['f0_'][0]\n",
    "print('*** Number of all records found:',num_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db787595",
   "metadata": {},
   "source": [
    "View the `query_2003_with_hash_vals` result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0109d08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>cigarette_use</th>\n",
       "      <th>alcohol_use</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.264232</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8045173873969881371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.563162</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16293285635216904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.209116</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>4931362078050829102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.316244</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7429616553140235181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.603743</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1781791737502110095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0       7.264232     True          22          1               39   \n",
       "1       6.563162     True          38          2               39   \n",
       "2       7.209116    False          18          1               41   \n",
       "3       6.316244     True          25          1               38   \n",
       "4       7.603743    False          23          1               39   \n",
       "\n",
       "  cigarette_use alcohol_use          hash_values  \n",
       "0       Unknown     Unknown  8045173873969881371  \n",
       "1       Unknown     Unknown    16293285635216904  \n",
       "2         false       false  4931362078050829102  \n",
       "3       Unknown     Unknown  7429616553140235181  \n",
       "4       Unknown     Unknown  1781791737502110095  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limit_100 = bq.query(query_2003_with_hash_vals + \"LIMIT 100\").to_dataframe()\n",
    "df_limit_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01ca2e",
   "metadata": {},
   "source": [
    "## Create ML dataset using Dataflow\n",
    "Let's use Cloud Dataflow to read in the BigQuery data, do some preprocessing, and write it out as CSV files.\n",
    "\n",
    "For the preprocessing, we'll do:\n",
    "\n",
    "- Modify plurality field to be a string where [1, 2, 3, 4, 5] becomes [\"Single(1)\", \"Twins(2)\", \"Triplets(3)\", \"Quadruplets(4)\", \"Quintuplets(5)\"]\n",
    "- Augment our dataset with our three simulated babyweight data by:\n",
    "    - setting all gender information to Unknown and setting plurality of all non-single births to Multiple(2+),\n",
    "    - setting cigarette_use information to Unknown,\n",
    "    - setting alcohol_use information to Unknown.\n",
    "    \n",
    "Fitst, let's define a function to create line(s) of CSV input from columns called by BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccf8cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(rowdict):\n",
    "    import hashlib\n",
    "    import copy\n",
    "    \n",
    "    CSV_COLUMNS = [\"weight_pounds\",\n",
    "                   \"is_male\",\n",
    "                   \"mother_age\",\n",
    "                   \"plurality\",\n",
    "                   \"gestation_weeks\",\n",
    "                   \"cigarette_use\",\n",
    "                   \"alcohol_use\"]\n",
    "\n",
    "    # Modify plurality field\n",
    "    rowdict_edited = copy.deepcopy(rowdict)\n",
    "    rowdict_edited['plurality'] = ['Single(1)', 'Twins(2)', 'Triplets(3)', 'Quadruplets(4)', 'Quintuplets(5)'][rowdict['plurality'] - 1]\n",
    "    \n",
    "    # Clone data and mask certain columns to simulate lack of ultrasound\n",
    "    no_ultrasound = copy.deepcopy(rowdict_edited)\n",
    "    no_ultrasound['is_male'] = 'Unknown'\n",
    "    no_ultrasound['plurality'] = 'Multiple(2+)' if rowdict['plurality'] > 1 else 'Single(1)'\n",
    "    \n",
    "    # Write out rows for each input row\n",
    "    for result in [rowdict_edited, no_ultrasound]:\n",
    "        data = ','.join([str(result[k]) if k in result else 'None' for k in CSV_COLUMNS])\n",
    "        #key = hashlib.sha224(data.encode('utf-8')).hexdigest()  # hash the columns to form a key\n",
    "        #yield str(f'{data},{key}')\n",
    "        yield str(f'{data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443c0a9",
   "metadata": {},
   "source": [
    "Dataflow job will start with a selection BigQuery, converting it to CSV, and writing the output as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52fdbb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(in_test_mode=True):\n",
    "    import shutil, os, subprocess\n",
    "    \n",
    "    HEADER = 'weight_pounds,is_male,mother_age,plurality,gestation_weeks,cigarette_use,alcohol_use'\n",
    "    job_name = 'preprocess-babyweight-features' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "\n",
    "    if in_test_mode:\n",
    "        print('Launching local job ... hang on')\n",
    "        OUTPUT_DIR = './datasets_preprocessed_Dataflow_test_mode'\n",
    "        shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "    else:\n",
    "        print(f'Launching Dataflow job {job_name} ... hang on')\n",
    "        OUTPUT_DIR = f'gs://{BUCKET}/datasets_preprocessed_Dataflow/'\n",
    "        try:\n",
    "            subprocess.check_call(f'gsutil -m rm -r {OUTPUT_DIR}'.split())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    options = {\n",
    "        'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "        'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'region': REGION,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True,\n",
    "    }\n",
    "    \n",
    "    opts = beam.pipeline.PipelineOptions(flags = [], **options)\n",
    "    if in_test_mode:\n",
    "        RUNNER = 'DirectRunner'\n",
    "    else:\n",
    "        RUNNER = 'DataflowRunner'\n",
    "        \n",
    "    p = beam.Pipeline(RUNNER, options = opts)\n",
    "    \n",
    "    query = query_2003_with_hash_vals\n",
    "    if in_test_mode:\n",
    "        query = query + ' LIMIT 100' \n",
    "    \n",
    "    for step in ['train', 'eval', 'test']:\n",
    "        if step == 'train':\n",
    "            selquery = f'SELECT * FROM ({query}) WHERE MOD(hash_values, 100) < 80'\n",
    "        elif step == 'eval':\n",
    "            selquery = f'SELECT * FROM ({query}) WHERE MOD(hash_values, 100) >= 80 AND MOD(hash_values, 100) < 90'\n",
    "        else:\n",
    "            selquery = f'SELECT * FROM ({query}) WHERE MOD(hash_values, 100) > 90'\n",
    "        (p \n",
    "         | f'{step}_read' >> beam.io.Read(beam.io.BigQuerySource(query = selquery, use_standard_sql = True))\n",
    "         | f'{step}_csv' >> beam.FlatMap(to_csv)\n",
    "         | f'{step}_out' >> beam.io.Write(beam.io.WriteToText(os.path.join(OUTPUT_DIR, f'{step}.csv'),header=HEADER))\n",
    "        )\n",
    "    job = p.run()\n",
    "    \n",
    "    if in_test_mode:\n",
    "        job.wait_until_finish()\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04515d0",
   "metadata": {},
   "source": [
    "First, let's test the `preprocess` function locally to see if it works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b4ca3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching local job ... hang on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset predict-babyweight-10142021:temp_dataset_048c92118c49496fa3a5a642693273db does not exist so we will create it as temporary with location=US\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset predict-babyweight-10142021:temp_dataset_1f82b2cf5be940bd9a79aae0c261bfbb does not exist so we will create it as temporary with location=US\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset predict-babyweight-10142021:temp_dataset_5705186c53e84038a94db1ff756115a7 does not exist so we will create it as temporary with location=US\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "preprocess(in_test_mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2b57e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_pounds,is_male,mother_age,plurality,gestation_weeks,cigarette_use,alcohol_use\n",
      "6.8673994613,False,27,Single(1),35,Unknown,Unknown\n",
      "6.8673994613,Unknown,27,Single(1),35,Unknown,Unknown\n",
      "5.68572173698,False,27,Single(1),36,false,false\n",
      "5.68572173698,Unknown,27,Single(1),36,false,false\n"
     ]
    }
   ],
   "source": [
    "!head -5 datasets_preprocessed_Dataflow_test_mode/train*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2e05c",
   "metadata": {},
   "source": [
    "Once everything has run correctly, let's execute the job in Cloud Dataflow. We can monitor the running job at the Dataflow section in the GCP web console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b16fe449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job preprocess-babyweight-features-211023-045809 ... hang on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding invalid overrides: {'teardown_policy': 'TEARDOWN_ALWAYS', 'no_save_main_session': True}\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding invalid overrides: {'teardown_policy': 'TEARDOWN_ALWAYS', 'no_save_main_session': True}\n"
     ]
    }
   ],
   "source": [
    "preprocess(in_test_mode = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b550a",
   "metadata": {},
   "source": [
    "After ~13 minutes, the job has been done. At this point, we now have the training and evaluation datasets created at scale. The process is also fully automated. We can simply re-run the pipeline periodically to create a new training dataset on fresher data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96720023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/eval.csv-00000-of-00006\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/eval.csv-00001-of-00006\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/eval.csv-00002-of-00006\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/eval.csv-00003-of-00006\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/eval.csv-00004-of-00006\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/eval.csv-00005-of-00006\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/test.csv-00000-of-00003\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/test.csv-00001-of-00003\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/test.csv-00002-of-00003\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00000-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00001-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00002-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00003-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00004-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00005-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00006-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00007-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00008-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00009-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00010-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00011-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00012-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00013-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00014-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00015-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00016-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00017-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00018-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00019-of-00020\n",
      "gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/tmp/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/datasets_preprocessed_Dataflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38d1f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_pounds,is_male,mother_age,plurality,gestation_weeks,cigarette_use,alcohol_use\n",
      "6.87621795178,False,18,Single(1),42,false,false\n",
      "6.87621795178,Unknown,18,Single(1),42,false,false\n",
      "6.81448851842,False,18,Single(1),42,Unknown,Unknown\n",
      "6.81448851842,Unknown,18,Single(1),42,Unknown,Unknown\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cat gs://predict-babyweight-10142021/datasets_preprocessed_Dataflow/train.csv-00000-of-00020 |head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e5210",
   "metadata": {},
   "source": [
    "## Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8e599",
   "metadata": {},
   "source": [
    "- Using Dataflow, we performed multiple preproseeing, modifying, and simulating data for the entire dataset and then produced CSV files for the training/evaluation datasets. \n",
    "- These files are storaged in the Cloud bucket and ready for the training a ML model at scale.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prepare_data_babyweight.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
